# auto generated by update_py.py

from collections import defaultdict
from typing import List, Optional, Type
from functools import partial
import os
import threading
import importlib
import datetime
import time
import sys
import enum
import traceback


# from sqlalchemy.dialects.mysql import insert
from read_protobuf import read_protobuf
import pandas as pd

from tlclient.linker.constant import FistType, HeartBeatStatus, ReadableEnum
from tlclient.linker.logger import get_log_default_path
from tlclient.trader.pb_msg.message_pb2 import GatewayPosition, GatewayTrades, RspAccount, Direction
from tlclient.trader.client import Client
from tlclient.trader.pb_msg import message_pb
from tlclient.trader.config import Configurator


SECONDS_TO_WAIT_FOR_CHECKING_TGS = 3
DEFAULT_SWITCH_DAY_TIME = datetime.time(16, 0, 0)
DEFAULT_REPORT_TIME = datetime.time(15, 22, 0)
DEFAULT_OURS_NAME = 'next_oms'
DEFAULT_ENV_NAME = 'env_oms'


class TradeDataTag(ReadableEnum, enum.IntEnum):

    TRADES = 1
    POSITION = 2
    ACCOUNT = 3


class NextOMSAlgoSPI:
    def __init__(self, ctx):
        self._ctx = ctx

    def on_insert_order(self, order_id: str, label: str):
        self._ctx.on_insert_order(order_id, label)

    def on_rsp_order_insert(self, obj, frame_nano):
        self._ctx.on_rsp_order_insert(obj, frame_nano)


class NextOMSDataAPIBase:

    def __init__(self, logger):
        self.logger = logger

    def init(self):
        pass

    # to be overrided
    def append_trade_data(self, tag: TradeDataTag, data) -> bool:
        pass

    # to be overrided
    def get_trade_signal(self) -> pd.DataFrame:
        pass

    # to be overrided
    def get_trade_targets(self) -> pd.DataFrame:
        pass

    # to be overrided
    def get_trading_day_list(self, start_date=None, end_date=None) -> Optional[pd.DataFrame]:
        pass

    # to be overrided
    def notify_simple_msg(self, msg: str, title: str):
        pass

    # to be overrided
    def init_db(self):
        pass


class NextOMS(Client):

    def _timer_t_func(self):
        report_time = getattr(self._oms_config, 'report_time', None)
        report_time = pd.to_datetime(report_time, infer_datetime_format=True).time() if report_time is not None else DEFAULT_REPORT_TIME
        self.logger.info(f'[_timer_t_func] started (report_time){report_time}')
        while not self.is_stopped():
            now_time = datetime.datetime.now()
            if now_time.time() >= report_time:
                self.logger.info(f'[_timer_t_func] to req reports (tg_list){self._tg_list}')
                if self._tg_list is not None:
                    for one_tg in self._tg_list:
                        for tag in [TradeDataTag.TRADES, TradeDataTag.POSITION, TradeDataTag.ACCOUNT]:
                            with self._tg_mg_lock:
                                if one_tg in self._tgs_processing[tag] or one_tg in self._tgs_done[tag]:
                                    continue
                            self.logger.info(f'[_timer_t_func] to req report on {one_tg} (tag){tag}')
                            with self._tg_mg_lock:
                                self._tgs_processing[tag].add(one_tg)
                            if tag == TradeDataTag.TRADES:
                                self.req_trades_today(one_tg)
                            elif tag == TradeDataTag.POSITION:
                                self.req_position(one_tg)
                            elif tag == TradeDataTag.ACCOUNT:
                                self.req_account(one_tg)

            time.sleep(60)
        self.logger.info(f'[_timer_t_func] stopping...')

    def __init__(self, algo_path: List[str], data_impl_file_path: str, fist_name=None):
        assert algo_path is not None, 'algo path must be a valid directory'
        self._algo_path = algo_path

        assert data_impl_file_path is not None, "datas' class file must be a valid file path"
        head, tail = os.path.split(data_impl_file_path)
        assert head and tail, f"datas' class file path is invalid (file_path){data_impl_file_path}"
        sys.path = [head] + sys.path
        try:
            data_impl_mod = importlib.import_module(tail.split('.')[0])
        except ModuleNotFoundError as e:
            print(f"can not import the data's class file (file_path){data_impl_file_path} (e){e}")
            raise e

        # load config
        # TODO: may support to reload
        oms_configs = {}
        for one in ('OMS_CONFIG_PATH', 'OMS_DB_MODE'):
            try:
                oms_configs[one] = os.environ[one]
            except KeyError:
                oms_configs[one] = None
        self._configure = Configurator(oms_configs['OMS_CONFIG_PATH'])
        self._oms_config = self._configure.get_oms_settings()
        env_name = getattr(self._oms_config, 'env_name', None)
        super().__init__(name=fist_name if fist_name is not None else DEFAULT_OURS_NAME, env_name=env_name if env_name is not None else DEFAULT_ENV_NAME, addr=self._configure._config['master_rep'])
        self.logger.info(f'[__init__] (oms_configs){oms_configs} (algo_path){self._algo_path} (data_impl_file_path){data_impl_file_path}')
        self._datas_api: Type[NextOMSDataAPIBase] = getattr(data_impl_mod, 'OMSDataAPI')(self._configure, self.logger)

        self._tg_mg_lock = threading.Lock()
        self._tg_mg_cv = threading.Condition(self._tg_mg_lock)
        self._tg_status = {}
        self._mg_status = {}
        self._algo_threads = {}
        self._tg_list = None
        self._tgs_processing = defaultdict(set)
        self._tgs_done = defaultdict(set)
        self._algo_lock = threading.Lock()
        self._algos_in_thread = {}
        self._timer_t = threading.Thread(target=self._timer_t_func, name=f'{self.fist_name}_timer')

    def init(self, trade_router=None, market_router=None):
        now_time = datetime.datetime.now()
        switch_day_time = getattr(self._oms_config, 'switch_day_time', None)
        switch_day_time = pd.to_datetime(switch_day_time, infer_datetime_format=True).time() if switch_day_time is not None else DEFAULT_SWITCH_DAY_TIME
        self.logger.info(f'[__init__] (now){now_time} (switch_day_time){switch_day_time}')
        if now_time.time() > switch_day_time:
            # next trading day
            today_date = now_time.date()
            trading_day_list = self._datas_api.get_trading_day_list(start_date=today_date)
            if trading_day_list is None or trading_day_list.shape[0] < 2:
                raise Exception(f'failed to get trading day list from DB (trading_day_list){trading_day_list}')
            trading_day_list = trading_day_list[trading_day_list.trade_date > today_date]
            self._the_date = trading_day_list.trade_date.sort_values().array[0]
        else:
            self._the_date = now_time.date()
        self.logger.info(f'[__init__] (the_date){self._the_date}')

        self._datas_api.init()
        self.init_trade('trade1' if trade_router is None else trade_router)
        self.init_market('market1' if market_router is None else market_router)

    # overrided
    def on_gateway_connection_change(self, obj, frame_nano):
        self.logger.info(f'[on_gateway_connection_change] (obj){obj} (frame_nano){frame_nano}')
        with self._tg_mg_lock:
            if obj.fist_type == FistType.TRADE_GATEWAY:
                self._tg_status[obj.fist_name] = obj.connected
            elif obj.fist_type == FistType.MARKET_GATEWAY:
                self._mg_status[obj.fist_name] = obj.connected

    # overrided
    def on_gateway_heart_beat(self, obj, frame_nano):
        self.logger.info(f'[on_gateway_heart_beat] (obj){obj} (frame_nano){frame_nano}')
        with self._tg_mg_lock:
            if obj.fist_type == FistType.TRADE_GATEWAY:
                self._tg_status[obj.fist_name] = obj.hb_status == HeartBeatStatus.HEALTHY
            elif obj.fist_type == FistType.MARKET_GATEWAY:
                self._mg_status[obj.fist_name] = obj.hb_status == HeartBeatStatus.HEALTHY

    # overrided
    def on_rsp_account(self, obj, frame_nano):
        self.logger.info(f'[on_rsp_account] (obj){obj} (frame_nano){frame_nano}')

        with self._tg_mg_lock:
            self._tg_status[obj.account_id] = True
            self._tg_mg_cv.notify_all()

            if obj.account_id in self._tgs_processing[TradeDataTag.ACCOUNT]:
                the_data = {}
                for one in obj.ListFields():
                    if one[0].name not in ('req_id'):
                        the_data[one[0].name] = one[1]
                the_data['date'] = self._the_date.isoformat()
                self.logger.info(f'[on_rsp_account] (the_data){the_data}')
                pd.Series(the_data).to_csv(f'{get_log_default_path()}/tmp_acc.csv')
                self._datas_api.append_trade_data(TradeDataTag.ACCOUNT, the_data)

                self._tgs_done[TradeDataTag.ACCOUNT].add(obj.account_id)
                self._tgs_processing[TradeDataTag.ACCOUNT].remove(obj.account_id)

    @staticmethod
    def _trans_direction(x: Direction) -> str:
        if x == Direction.DIRECTION_LONG:
            return 'LONG'
        elif x == Direction.DIRECTION_SHORT:
            return 'SHORT'
        return 'INVALID'

    # overrided
    def on_rsp_position(self, obj, frame_nano):
        self.logger.info(f'[on_rsp_position] (obj){obj} (frame_nano){frame_nano}')

        with self._tg_mg_lock:
            if obj.account_id in self._tgs_processing[TradeDataTag.POSITION]:

                is_done = False
                today_pos = obj.SerializeToString()
                try:
                    df = read_protobuf(today_pos, GatewayPosition, flatten=False)
                except (FileNotFoundError, ValueError) as e:
                    if (obj.err_id == 0) and (len(obj.positions) == 0):
                        self.logger.info(f'[on_rsp_position] empty data')
                        is_done = True
                    else:
                        self.logger.warning(f'[on_rsp_position] read_protobuf failed (e_type){type(e)} (e){e}')
                else:
                    filtered = []
                    for _, row in df.iterrows():
                        try:
                            if row.at['err_id'] != 0:
                                self.logger.warning(f'[on_rsp_position] err_id != 0 (row){row} (df){df}')
                                break
                        except KeyError:
                            pass
                        pos = row.positions
                        try:
                            # if (pos['position'] != 0) or (pos['yd_pos'] != 0):
                            filtered.append(pos)
                        except KeyError:
                            pass
                    else:
                        is_done = True
                        if filtered:
                            data_df = pd.DataFrame(filtered).drop(columns='security_type')
                            if isinstance(data_df, pd.Series):
                                data_df = data_df.to_frame().T
                            self.logger.info(f'[on_rsp_position] df after filtered\r\n{data_df}')
                            data_df['direction'] = data_df.direction.map(NextOMS._trans_direction)
                            data_df['exchange'] = data_df.exchange.map(lambda x: message_pb.Exchange.Name(x).split('_')[-1])
                            data_df['date'] = self._the_date.isoformat()
                            data_df['account_id'] = df.account_id.array[0]
                            for one in ['pnl', 'realized_pnl', 'unrealized_pnl', 'frz_pos', 'position', 'yd_pos', 'avail_pos', 'pos_cost', 'margin']:
                                if one in set(data_df.columns.array):
                                    data_df[one] = data_df[one].astype(str)
                            self.logger.info(f'[on_rsp_position] df final\r\n{data_df}')
                            data_df.to_csv(f'{get_log_default_path()}/tmp_pos.csv')
                            is_done = self._datas_api.append_trade_data(TradeDataTag.POSITION, data_df)
                        else:
                            self.logger.info(f'[on_rsp_position] empty data after filtered')

                self._tgs_done[TradeDataTag.POSITION].add(obj.account_id)
                self._tgs_processing[TradeDataTag.POSITION].remove(obj.account_id)
                if not is_done:
                    self._datas_api.notify_simple_msg(msg='failed to retrieve pos info', title=self._the_date)

    # overrided
    def on_rsp_trades_today(self, obj, frame_nano):
        '''
        处理请求查询当日成交的回报

        obj: GatewayTrades
        '''
        self.logger.info(f'[on_rsp_trades_today] (obj){obj} (frame_nano){frame_nano}')

        with self._tg_mg_lock:
            if obj.account_id in self._tgs_processing[TradeDataTag.TRADES]:

                is_done = False
                today_trades = obj.SerializeToString()
                try:
                    df = read_protobuf(today_trades, GatewayTrades, flatten=False)
                except (FileNotFoundError, ValueError) as e:
                    if (obj.err_id == 0) and (len(obj.trades) == 0):
                        self.logger.info(f'[on_rsp_trades_today] empty data')
                        is_done = True
                    else:
                        self.logger.warning(f'[on_rsp_trades_today] read_protobuf failed (e_type){type(e)} (e){e} (err_id){obj.err_id}')
                else:
                    filtered = []
                    for _, row in df.iterrows():
                        try:
                            if row.at['err_id'] != 0:
                                self.logger.warning(f'[on_rsp_trades_today] err_id != 0 (row){row} (df){df}')
                                break
                        except KeyError:
                            pass
                        filtered.append(row.trades)
                    else:
                        data_df = pd.DataFrame(filtered).drop(columns=['security_type', 'trade_time'])
                        if isinstance(data_df, pd.Series):
                            data_df = data_df.to_frame().T
                        self.logger.info(f'[on_rsp_trades_today] df after filtered\r\n{data_df}')
                        data_df['side'] = data_df.side.map(lambda x: message_pb.Side.Name(x).split('_')[-1])
                        data_df['exchange'] = data_df.exchange.map(lambda x: message_pb.Exchange.Name(x).split('_')[-1])
                        data_df['offset_flag'] = data_df.offset_flag.map(lambda x: message_pb.OffsetFlag.Name(x).split('_')[-1])
                        if 'order_type' in data_df.columns:
                            data_df['order_type'] = data_df.order_type.map(lambda x: message_pb.OrderType.Name(x).split('_')[-1])
                        data_df['date'] = self._the_date.isoformat()
                        for one in ['order_id']:
                            if one in set(data_df.columns.array):
                                data_df[one] = data_df[one].astype(str)
                        data_df['account_id'] = df.account_id.array[0]
                        self.logger.info(f'[on_rsp_trades_today] df final\r\n{data_df}')
                        data_df.to_csv(f'{get_log_default_path()}/tmp_trades.csv')
                        # self.logger.info(f'[on_rsp_trades_today] (columns){data_df.columns.to_list()} (records){data_df.to_dict(orient="records")}')
                        is_done = self._datas_api.append_trade_data(TradeDataTag.TRADES, data_df)

                self._tgs_done[TradeDataTag.TRADES].add(obj.account_id)
                self._tgs_processing[TradeDataTag.TRADES].remove(obj.account_id)
                if not is_done:
                    self._datas_api.notify_simple_msg(msg='failed to retrieve trades info', title=self._the_date)

    # def on_insert_order(self, order_id: str, label: str):
    #     self.logger.info(f'[on_insert_order] (order_id){order_id} (label){label}')
    #     with DatabaseConnector().managed_session() as session:
    #         insert_stmt = insert(OrderInfo).values(
    #             order_id=order_id,
    #             label=label
    #         )
    #         on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(
    #             label=insert_stmt.inserted.label,
    #         )
    #         result = session.execute(on_duplicate_key_stmt)
    #         self.logger.info(f'[on_insert_order] (stmt){on_duplicate_key_stmt} (result){result}')
    #         session.commit()

    # overrided
    # def on_rsp_order_insert(self, obj, frame_nano):
    #     self.logger.info(f'[on_rsp_order_insert] (obj){obj} (frame_nano){frame_nano}')
    #     with DatabaseConnector().managed_session() as session:
    #         insert_stmt = insert(OrderInfo).values(
    #             order_id=obj.order_id,
    #             order_ref=obj.order_ref,
    #         )
    #         on_duplicate_key_stmt = insert_stmt.on_duplicate_key_update(
    #             order_ref=insert_stmt.inserted.order_ref,
    #         )
    #         result = session.execute(on_duplicate_key_stmt)
    #         self.logger.info(f'[on_rsp_order_insert] (stmt){on_duplicate_key_stmt} (result){result}')
    #         session.commit()

    # overrided
    def on_close(self):
        self.logger.info('[on_close]')
        super().on_close()

        with self._tg_mg_lock:
            self._tg_mg_cv.notify_all()

    def _tg_mg_cv_func(self, tg_list) -> bool:
        if self.is_stopped():
            return True

        results = {}
        for one in tg_list:
            try:
                if self._tg_status[one]:
                    results[one] = True
            except KeyError:
                pass
        if (sorted(tg_list) == sorted(results.keys())) and all(results.values()):
            return True
        return False

    def _check_tgs(self, tg_list: List[str]):
        results = {}
        with self._tg_mg_lock:
            for one in tg_list:
                try:
                    if self._tg_status[one]:
                        results[one] = True
                except KeyError:
                    pass
        tg_list_set = set(tg_list)
        results_key_set = set(results.keys())
        if (tg_list_set == results_key_set) and all(results.values()):
            return
        to_check_again = tg_list_set - results_key_set
        self.logger.info(f'[check_tgs] tgs to check (part1) {to_check_again}')
        to_check_again |= set([k for k, v in results.items() if not v])
        self.logger.info(f'[check_tgs] tgs to check (all) {to_check_again}')
        return list(to_check_again)

    def check_tgs(self, tg_list: List[str]) -> Optional[List[str]]:
        self.logger.info(f'[tg_list] to check tgs {tg_list}')
        to_check_again = self._check_tgs(tg_list)
        if to_check_again is None:
            self.logger.info(f'[check_tgs] all tgs in {tg_list} are ready')
            return

        for one in to_check_again:
            self.logger.info(f'[check_tgs] req account on {one}')
            self.req_account(one)
        with self._tg_mg_cv:
            result = self._tg_mg_cv.wait_for(partial(self._tg_mg_cv_func, tg_list), timeout=SECONDS_TO_WAIT_FOR_CHECKING_TGS)
        if self.is_stopped():
            self.logger.warning('[check_tgs] signal received, exit now')
        if result:
            self.logger.info(f'[check_tgs] all tgs in {tg_list} are ready')
            return

        self.logger.error('[check_tgs] to check tgs last time')
        return self._check_tgs(tg_list)

    def _algo_thread_func(self, method, account, algo_method, targets_df):
        try:
            the_algo = getattr(algo_method, 'TradeExecutor')(method, account, self._configure, NextOMSAlgoSPI(self))
            with self._algo_lock:
                self._algos_in_thread[(method, account)] = the_algo
            the_algo.init(targets_df)
            the_algo.start()
            the_algo.join()
        except Exception as e:
            msg = f'(e){e} (e_type){type(e)} tb:\n{traceback.format_exc()}'
            self._datas_api.notify_simple_msg(msg=msg, title=self._the_date)
            self.logger.info(msg)

    def _groupby_func2(self, method, algo_method, x):
        account = x.account.array[0]
        self.logger.info(f'[_groupby_func2] (method){method} (algo_method){algo_method} (account){account} (x){x}')
        t = threading.Thread(target=self._algo_thread_func, name=method, daemon=False, kwargs={
            'method': method,
            'account': account,
            'algo_method': algo_method,
            'targets_df': x.copy(),
        })
        self._algo_threads[(method, account)] = t
        self.logger.info(f'[_groupby_func2] to start a trade executor (method){method} (targets):\r\n{x}')
        t.start()

    def _groupby_func(self, x):
        method = x.method.array[0]
        sys.path = self._algo_path + sys.path
        try:
            algo_method = importlib.import_module(method)
        except ModuleNotFoundError as e:
            msg = f'can not import the method module (method){method} (e){e}'
            self.logger.warning(msg)
            self._datas_api.notify_simple_msg(msg=msg, title=self._the_date)
            return

        x.groupby(by='account', sort=False).apply(partial(self._groupby_func2, method, algo_method))

    def start(self):
        super().start()
        # read from mysql
        # with DatabaseConnector().managed_session() as session:
        #     try:
        #         query = session.query(
        #             Targets
        #         ).filter(
        #             Targets.trading_day == self._the_date,
        #         )
        #         targets_df = pd.read_sql(query.statement, query.session.bind)
        #     except Exception as e:
        #         self.logger.error(f'Failed to get data <err_msg> {e} from {Targets.__tablename__}')

        # check the signal if it's confirmed
        while not self.is_stopped():
            signal_df = self._datas_api.get_trade_signal()
            signal_df = signal_df[signal_df.date == self._the_date]
            self.logger.info(f'(signal_df final)\r\n{signal_df}')
            is_confirmed = False
            if not signal_df.empty:
                the_key_item = signal_df.loc[signal_df.update_time.idxmax(), :]
                if the_key_item.confirm == 'Yes':
                    is_confirmed = True
                else:
                    msg = f'[start] not confirmed, wait some seconds to recheck'
                    self._datas_api.notify_simple_msg(msg=msg, title=self._the_date)
                    self.logger.info(f'{msg} (today){self._the_date}')
            else:
                msg = f'[start] no signal item today, wait some seconds to recheck'
                self._datas_api.notify_simple_msg(msg=msg, title=self._the_date)
                self.logger.info(f'{msg} (today){self._the_date}')
            if is_confirmed:
                self.logger.info(f'[start] confirmed, next step (today){self._the_date}')
                break
            time.sleep(60)
        else:
            self.logger.info(f'[start] stopped, exit now... (today){self._the_date}')
            return

        targets_df = self._datas_api.get_trade_targets()
        targets_df = targets_df[targets_df.trading_day == self._the_date]
        if targets_df.empty:
            self.logger.info(f'[start] empty target, exit now... (today){self._the_date}')
            return

        self.logger.info(f'[start] (targets df){targets_df}')
        tg_list = list(set(targets_df.account.array))
        result = self.check_tgs(tg_list)
        if result is not None and result:
            msg = f'tg(s) {result} is(are) not ready'
            self._datas_api.notify_simple_msg(msg=msg, title=self._the_date)
            time.sleep(2)
            raise Exception(msg)
        self._tg_list = tg_list

        self.logger.info(f'[start] to start trade executors')
        targets_df.groupby(by='method', sort=False).apply(self._groupby_func)

        # 在最后再启动它
        self._timer_t.start()

    def join(self):
        super().join()

        for (method, account), t in self._algo_threads.items():
            if t.is_alive():
                with self._algo_lock:
                    obj = self._algos_in_thread[(method, account)]
                obj.stop()
                t.join()
            self.logger.info(f'[join] (method){method} (account){account} done')
        if self._timer_t.is_alive():
            self._timer_t.join()

    def test_req(self, tag, tg_name):
        with self._tg_mg_lock:
            self._tgs_processing[tag].add(tg_name)
        if tag == TradeDataTag.TRADES:
            self.req_trades_today(tg_name)
        elif tag == TradeDataTag.POSITION:
            self.req_position(tg_name)
        elif tag == TradeDataTag.ACCOUNT:
            self.req_account(tg_name)

    def refresh_reqs(self, tg_list: List[str]):
        super().start()
        self._tg_list = tg_list
        self._timer_t.start()

